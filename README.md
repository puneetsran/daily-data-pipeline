# ğŸ“Š Daily Data Pipeline Showcase

[![Data Pipeline](https://github.com/puneetsran/daily-data-pipeline/actions/workflows/daily-pipeline.yml/badge.svg)](https://github.com/puneetsran/daily-data-pipeline/actions/workflows/daily-pipeline.yml)
[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

An automated data engineering project that demonstrates ETL pipeline skills using GitHub Actions. This pipeline runs daily to collect, process, and visualize data automatically.

## ğŸ¯ Project Overview

This project showcases:
- **Automated ETL Pipeline**: Scheduled data collection and processing
- **CI/CD with GitHub Actions**: Fully automated workflow
- **Data Engineering Best Practices**: Clean code, error handling, logging
- **Real-time Data Processing**: Daily updates without manual intervention
- **Data Visualization**: Auto-generated insights and charts

## ğŸ“ˆ Current Data Insights

### GitHub Trending Repositories (Last Updated: 2026-01-14 01:08:16 UTC)
| Repository | Stars | Language | Description |
|------------|-------|----------|-------------|
| [codecrafters-io/build-your-own-x](https://github.com/codecrafters-io/build-your-own-x) | 456,249 | Markdown | Master programming by recreating your favorite technologies from scratch. |
| [freeCodeCamp/freeCodeCamp](https://github.com/freeCodeCamp/freeCodeCamp) | 435,818 | TypeScript | freeCodeCamp.org's open-source codebase and curriculum. Learn math, programming,... |
| [sindresorhus/awesome](https://github.com/sindresorhus/awesome) | 429,292 | N/A | ğŸ˜ Awesome lists about all kinds of interesting topics |
| [public-apis/public-apis](https://github.com/public-apis/public-apis) | 390,947 | Python | A collective list of free APIs |
| [EbookFoundation/free-programming-books](https://github.com/EbookFoundation/free-programming-books) | 380,432 | Python | :books: Freely available programming books |

### Weather Data Summary

| Metric | Value |
|--------|-------|
| City Tracked | Vancouver |
| Average Temperature | 11.0Â°C (53.0Â°F) |
| Average Humidity | 100% |
| Data Points | 1 |

## ğŸ› ï¸ Tech Stack

- **Language**: Python 3.9+
- **Libraries**: pandas, requests, matplotlib, seaborn
- **Automation**: GitHub Actions
- **Data Storage**: CSV/JSON in repository
- **Scheduling**: Cron (daily at 00:00 UTC)

## ğŸš€ Pipeline Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GitHub Actions â”‚
â”‚   (Scheduler)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Collectionâ”‚
â”‚   (API Calls)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data Processing â”‚
â”‚ (pandas/Python) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Storage   â”‚
â”‚   (CSV/JSON)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ README Update   â”‚
â”‚ (Auto-generated)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
daily-data-pipeline/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ daily-pipeline.yml    # GitHub Actions workflow
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # Raw data from APIs
â”‚   â”œâ”€â”€ processed/                # Cleaned and processed data
â”‚   â””â”€â”€ archive/                  # Historical data
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ collect_data.py           # Data collection script
â”‚   â”œâ”€â”€ process_data.py           # Data processing script
â”‚   â””â”€â”€ update_readme.py          # README auto-update script
â”œâ”€â”€ visualizations/               # Generated charts and graphs
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸ”„ Automation Details

The pipeline runs automatically:
- **Schedule**: Daily at 00:00 UTC
- **Trigger**: Can also be manually triggered
- **Duration**: ~2-3 minutes per run
- **Cost**: $0 (GitHub Actions free tier)

## ğŸ“Š Data Sources

1. **GitHub Trending API**: Top trending repositories
2. **OpenWeather API**: Weather data for major cities
3. **Public APIs**: Various free data sources

## ğŸ“ Learning Outcomes

This project demonstrates:
- âœ… Building production-ready data pipelines
- âœ… Implementing CI/CD workflows
- âœ… Working with REST APIs
- âœ… Data cleaning and transformation
- âœ… Automated reporting and visualization
- âœ… Git workflow and version control
- âœ… Error handling and logging

## ğŸš¦ Getting Started

### Prerequisites
```bash
python 3.9+
pip
git
```

### Local Setup
```bash
# Clone the repository
git clone https://github.com/puneetsran/daily-data-pipeline.git
cd daily-data-pipeline

# Install dependencies
pip install -r requirements.txt

# Run the pipeline manually
python scripts/collect_data.py
python scripts/process_data.py
python scripts/update_readme.py
```

## ğŸ“ License

MIT License - feel free to use this project as a template for your own data pipelines!

## ğŸ‘¤ Author

**Puneet Sran**
- Portfolio: [puneetsran.github.io/portfolio-website](https://puneetsran.github.io/portfolio-website/)
- GitHub: [@puneetsran](https://github.com/puneetsran)
- LinkedIn: [puneetsran](https://www.linkedin.com/in/puneetsran/)

---

*This README is automatically updated by the data pipeline. Last update: 2026-01-14 01:08:16 UTC*
